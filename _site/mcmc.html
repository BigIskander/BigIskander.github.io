<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Реализация алгоритма Metropolis-Hastings MCMC в R для случая нескольких переменных.</title>
  <!-- favicon (https://realfavicongenerator.net) -->
  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
  <link rel="manifest" href="/favicon/site.webmanifest">
  <link rel="mask-icon" href="/favicon/safari-pinned-tab.svg" color="#5bbad5">
  <link rel="shortcut icon" href="/favicon/favicon.ico">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-config" content="/favicon/browserconfig.xml">
  <meta name="theme-color" content="#ffffff">
  <!-- favicon end -->
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-1SRVHMPS1J"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-1SRVHMPS1J');
  </script>
  <!-- Google tag END -->
  <script src="/assets/js/all.js"></script>
  
  <!-- https://prismjs.com -->
  <!-- for code highlight -->
  <link href="/assets/css/prism.css" rel="stylesheet" />
  <script src="/assets/js/prism.js"></script>
  <script src="/assets/js/show_hide_code.js"></script>
  
  
  <!-- https://www.mathjax.org -->
  <!-- scripts for formulas demonstration -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  
  <link rel="stylesheet" href="/assets/css/styles.css">
  </head>
  <body onload="pageOnLoad()" onscroll="pageOnScrollDo()" onresize="pageOnResize()">
	<div class="content">
    <div class="header">
    </div>
	<div class="menu">
<a href="/" class="menu_link" >Главная</a><a href="/blog.html" class="menu_link" >Блог</a><a href="/xuexihanzi_mobile.html" class="menu_link" >Учить китайские слова</a><a href="/mcmc.html" class="menu_link_selected" >MCMC algorithm</a>
</div>

  <h1>Реализация алгоритма Metropolis-Hastings MCMC в R для случая нескольких переменных.</h1>
<p>03 Dec 2022</p>
<p>Это реализация алгоритма Metropolis-Hastings MCMC, которую я применял в своих расчетах.</p>
<p>В виде формул я уже описывал этот алгоритм в своей статье: <b><i>Султанов И.Р. Прогнозирование спредов доходности на первичном рынке российских рублевых корпоративных облигаций // Горизонты экономики. - 2019. - Vol. 1 (47). - P. 62–73.</i></b> (<a href="https://elibrary.ru/item.asp?id=37106647" target="_blank">ссылка на публикацию</a>)
<br>Здесь приводится непосредственно реализация алгоритма (исходный код в R).
<br>Возможно, кому то пригодится. Удачи в ваших исследованиях. </p>
<p>Для написания собственной реализации алгоритма за основу взял:
<ol>
<li>
пример реализации алгоритма MCMC для случая одной переменной: <b><i>Wiecki T. MCMC sampling for dummies. Available at: <a href="http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/" target="_blank">http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/ </a>(accessed 20.06.2017).</i></b>
</li><li>
формулы для расчетов из статьи: <b><i>Айвазян С.А. Байесовский подход в эконометрическом анализе // Прикладная эконометрика. - 2008. - Vol. 9. - Is. 1. - P. 93–130.</i></b></li>
</ol>
</p>
<p>
В общем виде оцениваемая эконометрическая модель может быть записана как:
\[y={{\theta }_{0}}+{{\theta }_{1}}*{{x}^{(1)}}+{{\theta }_{2}}*{{x}^{(2)}}+...+{{\theta }_{k}}*{{x}^{(k)}}+\varepsilon \]
</p><p>
В матричной записи формула принимает вид:
$$Y=X\theta +\varepsilon $$
где \(Y={{\left( {{y}_{1}},{{y}_{2}},\ldots ,{{y}_{n}} \right)}^{T}}\)
– значения зависимой переменной,
\(n\)
– число наблюдений;
\(X=\left[ \begin{matrix}
   1 & x_{1}^{\left( 1 \right)} & \ldots  & x_{1}^{\left( k \right)}  \\
   1 & x_{2}^{\left( 1 \right)} & \ldots  & x_{2}^{\left( k \right)}  \\
   \ldots  & \ldots  & \ldots  & \ldots   \\
   1 & x_{n}^{\left( 1 \right)} & \ldots  & x_{n}^{\left( k \right)}  \\
\end{matrix} \right]\)
– значения независимых переменных (верхний индекс – номер переменной, нижний индекс – номер наблюдения);
\(\theta ={{\left( {{\theta }_{0}},{{\theta }_{1}},\ldots ,{{\theta }_{k}} \right)}^{T}}\)
– значения параметров модели,
\(k\)
– число переменных;
\(\varepsilon ={{\left( {{\varepsilon }_{1}},{{\varepsilon }_{2}},\ldots ,{{\varepsilon }_{n}} \right)}^{T}}\)
– значения остатков модели (регрессии);
\(\varepsilon \in {{N}_{n}}\left( 0;\frac{1}{h}{{I}_{n}} \right)\)
– распределение остатков,
где \(h=\frac{1}{D\varepsilon }\),
\(D\varepsilon =var\left( \varepsilon  \right)\),
\({{I}_{n}}\) – единичная матрица размерности \(n\).</p>

<hr>
<p>
Для определения первоначальных значений параметров, cначала рассчитывались оценки коэффициентов модели и
остатки регрессии обычным методом МНК (метод наименьших квадратов) на данных за
предыдущие периоды (годы).</p>
<div class="code">
<div class="code_header">
  <a onclick="show_hide('code_1')" href="javascript:void(0);">Код в R (<em>показать</em>):</a>
</div>
<div id="code_1" class="code_lines_hide">
<pre><code class="language-R line-numbers">#estimate linear regressions
m1 &lt;- lm(f, mydata, year==2007)
m2 &lt;- lm(f, mydata, year==2008)
m3 &lt;- lm(f, mydata, year==2009)
m4 &lt;- lm(f, mydata, year==2010)
m5 &lt;- lm(f, mydata, year==2011)
m6 &lt;- lm(f, mydata, year==2012)
m7 &lt;- lm(f, mydata, year==2013)
m8 &lt;- lm(f, mydata, year==2014)

#get thetas from coefficients
cf1 &lt;- coef(m1)
cf2 &lt;- coef(m2)
cf3 &lt;- coef(m3)
cf4 &lt;- coef(m4)
cf5 &lt;- coef(m5)
cf6 &lt;- coef(m6)
cf7 &lt;- coef(m7)
cf8 &lt;- coef(m8)</code></pre>
</div></div>
<!-- Продолжение -->
<hr>
<p>
Затем, начальные значения параметров брались, как
\({{\theta }_{i}}=\frac{\sum\limits_{j=1}^{s}{\theta _{i}^{t-j}}}{s}\)
– начальное значение коэффициента \(i\)
(верхний индекс обозначает номер года, \(\theta _{i}^{t-j}\)
- параметр \(i\) оцененный на данных за год \(t - j)\);
\(h=\frac{\sum\limits_{j=1}^{s}{{{h}^{t-j}}}}{s}\)
– (верхний индекс обозначает номер года);
\({{\sigma }_{i}}=\sqrt{D{{\theta }_{i}}}\);
\({{\sigma }_{h}}=\sqrt{Dh}\);
(\(h=\frac{1}{D\varepsilon }\);
\(D\varepsilon =var\left( \varepsilon  \right)\)).
</p>
<div class="code">
  <div class="code_header">
    <a onclick="show_hide('code_2')" href="javascript:void(0);">Код в R (<em>показать</em>):</a>
  </div>
  <div id="code_2" class="code_lines_hide">
<pre><code class="language-R line-numbers">#primary estimations
hh &lt;- 1/c(var(residuals(m1)),var(residuals(m2)),
          var(residuals(m3)),var(residuals(m4)),
          var(residuals(m5)),var(residuals(m6)),
          var(residuals(m7)),var(residuals(m8)))
h &lt;- mean(hh)
st_h &lt;- sqrt(var(hh))</code></pre>
</div></div>
<!-- Продолжение -->
<hr>
<p>Параметры модели (т.е. переменные \(\theta \) и \(h\)) рассматривались, как показатели,
подчиняющиеся многомерному гамма-нормальному распределению
\(E\theta =Et(2a|\theta ;\frac{\alpha }{\beta }\Lambda )\),
где \(t(…,…)\) – многомерное обобщенное распределение Стьюдента.
Параметры распределения рассчитывались как
\(\alpha =\frac{{{h}^{2}}}{{{\sigma }_{h}}^{2}}\);
\(\beta =\frac{h}{{{\sigma }_{h}}^{2}}\);
\(\Lambda =\left[ \begin{matrix}
   {{\lambda }^{\left( 0 \right)}} & 0 & \ldots  & 0  \\
   0 & {{\lambda }^{\left( 1 \right)}} & \ldots  & 0  \\
   \ldots  & \ldots  & \ldots  & \ldots   \\
   0 & 0 & \ldots  & {{\lambda }^{\left( k \right)}}  \\
\end{matrix} \right]\) (25).
Где \({{\lambda }^{\left( j \right)}}=\left| \frac{1}{{{\sigma }_{j}}^{2}}\cdot \frac{\beta }{\alpha -1} \right|\)
</p>
<div class="code">
  <div class="code_header">
    <a onclick="show_hide('code_3')" href="javascript:void(0);">Код в R (<em>показать</em>):</a>
  </div>
<div id="code_3" class="code_lines_hide">
<pre><code class="language-R line-numbers">#calc the distribution params
alpha &lt;- (h^2)/(st_h^2)
beta &lt;- h/(st_h^2)

ll &lt;- length(cf1)

cfl &lt;- matrix(0, ll, 8)
th &lt;- matrix(0, ll, 1)
st_th &lt;- matrix(0, ll, 1)
#L matrix calculation
L &lt;- matrix(0, ll, ll)
for(i in 1:ll)
{
  cfl[i,] &lt;- c(cf1[i],cf2[i],cf3[i],cf4[i],cf5[i],
               cf6[i],cf7[i],cf8[i])
  th[i] &lt;- mean(cfl[i,])
  st_th[i] &lt;- sqrt(var(cfl[i,]))
  L[i,i] &lt;- (1/(st_th[i]^2))*(beta/(alpha-1))
}</code></pre>
</div></div>
<!-- Продолжение -->
<hr>
<p>
Далее параметры модели оценивались на новых данных.
Для расчетов методом Metropolis-Hastings MCMC применялась функция с названием <b>mcmc</b>
речь о которой пойдет далее.
</p>
<div class="code">
  <div class="code_header">
    <a onclick="show_hide('code_4')" href="javascript:void(0);">Код в R (<em>показать</em>):</a>
  </div>
<div id="code_4" class="code_lines_hide">
<pre><code class="language-R line-numbers">#get X and Y
ndata &lt;- subset(mydata, year==2015)
M &lt;- as.matrix(model.frame(formula=f, data=ndata))
Y &lt;- M[,1]
X &lt;- cbind(1,M[,-1])
n &lt;- length(Y)

iter &lt;- 10000
data &lt;- mcmc(iter, X, Y, th, alpha, beta, h, L)

#get model parameters from MCMC estimation
th_sim &lt;- matrix(0,ncol(data)-1,1)
for(i in 2:ncol(data)) th_sim[i-1] &lt;- rbind(mean(data[,i]))</code></pre>
</div></div>
<!-- Продолжение -->
<hr>
<p>
<b>Содержимое функции mcmc.</b>
Первоначальные значения параметров перед запуском алгоритма Metropolis-Hastings MCMC рассчитывались, как:
\({{S}_{a}}=w*S\);
\(S=\left( {{S}_{1}},\ldots ,{{S}_{i}} \right)\);
\({{S}_{i}}=\frac{1}{\sqrt{{{c}_{i}}}}\);
\({{c}_{i}}={{b}_{ii}}-{{B}_{i.}}B{{\left( i \right)}^{-1}}{{B}_{.i}}\);
\(B=\left[ \begin{matrix}
     {{b}_{ii}} & {{B}_{i.}}  \\
     {{B}_{.i}} & B\left( i \right)  \\
  \end{matrix} \right]\);
  \(B=\frac{\alpha }{\beta }\Lambda \);
  \(w=1\) (позволяет регулировать процент принятия новых значений или acceptance rate).
</p><p>
<div class="code">
<div class="code_header">
    <a onclick="show_hide('code_5')" href="javascript:void(0);">Код в R (<em>показать</em>):</a>
  </div>
<div id="code_5" class="code_lines_hide">
<pre><code class="language-R line-numbers">#preliminary estimation 1
B &lt;- h*L
C &lt;- matrix(0, length(b_TH), 1)
for(i in 1:length(b_TH))
{
  C[i] &lt;- B[i,i]-B[i,-i]%*%solve(B[-i,-i],B[-i,i])
}
stdp &lt;- 1/sqrt(C)</code></pre>
</div></div>
</p>
<!-- Продолжение -->
<hr>
<p>
Первоначальные значения элементов цепи (до запуска алгоритма) рассчитывались следующим образом:
\(~M=\left( {{M}_{1}},\ldots ,{{M}_{q}} \right)\);
\({{Y}_{p}}=X\theta \);
\({{\vartheta }_{pr}}=var\left( Y-{{Y}_{p}} \right)\);
\({{M}_{1}}=\left( {{\vartheta }_{pr}};\theta  \right)\);
\({{P}_{pr}}=apost\left( {{Y}_{p}};{{\vartheta }_{pr}};\theta  \right)\);
\({{\theta }_{pv}}=\theta \).
Где \(M\) – марковская цепь; \(q\) – длина цепи;
\(apost(…;…;…)\)
– функция расчета апостериорной вероятности (в программе названа как aposterior).
</p>
<div class="code">
<div class="code_header">
  <a onclick="show_hide('code_7')" href="javascript:void(0);">Код в R (<em>показать</em>):</a>
</div>
<div id="code_7" class="code_lines_hide">
<pre><code  class="language-R line-numbers">#preliminary estimation 2
iter &lt;- iter*1.1
b &lt;- b_TH
pY &lt;- X%*%b
resid &lt;- Y-pY
sig_sq &lt;- as.numeric(var(resid))
output=matrix(0,ncol=ncol(X)+1,nrow=iter)
output[1,]=c(sig_sq,b)

prevp &lt;- aposterior(b, sig_sq, b_TH, alpha, beta, stdp, Y, pY)</code></pre>
</div></div>
<!-- Продолжение --->
<hr>
<p>
Далее, начиная со второго элемента, каждый следующий элемент последовательно рассчитывался так:
\({{\theta }^{*}}=prop\left( {{\theta }_{pv}};{{S}_{a}} \right)\);
\({{Y}_{p}}=X{{\theta }^{*}}\);
\({{\vartheta }^{*}}=var\left( Y-{{Y}_{p}} \right)\); если
\(r&lt;\frac{apost\left( {{Y}_{p}}\;{{\vartheta }^{*}};{{\theta }^{*}} \right)}{{{P}_{pr}}}\),
то {\({{M}_{i}}=\left( {{\vartheta }^{*}};{{\theta }^{*}} \right)\); \({{\vartheta }_{pr}}={{\vartheta }^{*}}\);
\({{\theta }_{pv}}={{\theta }^{*}}\); \({{P}_{pr}}=apost\left( {{Y}_{p}};{{\vartheta }^{*}};{{\theta }^{*}} \right)\)}
иначе {\({{M}_{i}}=\left( {{\vartheta }_{pr}};{{\theta }_{pv}} \right)\)},
где \(r\) – случайное число из равномерного распределения на отрезке \([0;1]\)};
\(prop\left( {{\theta }_{pv}};{{S}_{a}} \right)\) – функция,
случайным образом генерирующая вектор чисел из нормального распределения со средними
\({{\theta }_{pv}}\) и стандартными отклонениями   (при этом предполагается, что отдельные числа входящие в вектор независимы между собой).
При практических расчетах значения вероятностей заменялись значениями логарифмов вероятности,
так как в этом случае деление вероятностей заменяется вычитанием логарифмов вероятностей и расчеты происходят значительно быстрее.
</p>
<div class="code">
<div class="code_header">
  <a onclick="show_hide('code_8')" href="javascript:void(0);">Код в R (<em>показать</em>):</a>
</div>
<div id="code_8" class="code_lines_hide">
<pre><code  class="language-R line-numbers">#mcmc algorithm main cycle
i &lt;- 2
while(i&lt;=iter)
{
  bn &lt;- propose(b, stdp)
  pY &lt;- X%*%bn
  residn &lt;- Y-pY
  sig_sqn &lt;- as.numeric(var(residn))
  ace &lt;- aposterior(bn, sig_sqn, b_TH, alpha, beta, stdp, Y, pY)
  if(log(runif(1))&lt;(ace-prevp)) {
    b &lt;- bn
    sig_sq &lt;- sig_sqn
    prevp &lt;- ace
  }
  output[i,]=c(sig_sq,b)
  i &lt;- i+1
}
</code></pre>
</div></div>
<hr>
<p><b>Функция mcmc, полностью:</b></p>
<div class="code">
<div class="code_header">
  <a onclick="show_hide('code_9')" href="javascript:void(0);">Код в R (<em>показать</em>):</a>
</div>
<div id="code_9" class="code_lines_hide">
<pre><code  class="language-R line-numbers">#mcmc simulation
#iter - number of iterations
#X, Y - curent data
#b_TH - vector of coeffients from previous data estimation
#alpha, beta - gamma distribution parameters from previous data estimation
#h, L - accuracy variables from previous data estimation
mcmc &lt;- function(iter, X, Y, b_TH, alpha, beta, h, L)
{
  #preliminary estimation 1
  B &lt;- h*L
  C &lt;- matrix(0, length(b_TH), 1)
  for(i in 1:length(b_TH))
  {
    C[i] &lt;- B[i,i]-B[i,-i]%*%solve(B[-i,-i],B[-i,i])
  }
  stdp &lt;- 1/sqrt(C)

  #preliminary estimation 2
  iter &lt;- iter*1.1
  b &lt;- b_TH
  pY &lt;- X%*%b
  resid &lt;- Y-pY
  sig_sq &lt;- as.numeric(var(resid))
  output=matrix(0,ncol=ncol(X)+1,nrow=iter)
  output[1,]=c(sig_sq,b)

  prevp &lt;- aposterior(b, sig_sq, b_TH, alpha, beta, stdp, Y, pY)

  #mcmc algorithm main cycle
  i &lt;- 2
  while(i&lt;=iter)
  {
    bn &lt;- propose(b, stdp)
    pY &lt;- X%*%bn
    residn &lt;- Y-pY
    sig_sqn &lt;- as.numeric(var(residn))
    ace &lt;- aposterior(bn, sig_sqn, b_TH, alpha, beta, stdp, Y, pY)
    if(log(runif(1))&lt;(ace-prevp)) {
      b &lt;- bn
      sig_sq &lt;- sig_sqn
      prevp &lt;- ace
    }
    output[i,]=c(sig_sq,b)
    i &lt;- i+1
  }
  return(output[-c(1:(iter/11)),])
}
</code></pre>
</div></div>
<hr>
<p>Функция \(prop(...,...)\) (в программе названа как propose) функция,
  случайным образом генерирующая вектор чисел из нормального распределения.</p>
<div class="code">
<div class="code_header">
  <a onclick="show_hide('code_10')" href="javascript:void(0);">Код в R (<em>показать</em>):</a>
</div>
<div id="code_10" class="code_lines_hide">
<pre><code  class="language-R line-numbers">#generate new varibles
propose &lt;- function(b, st)
{
  return(rnorm(length(b),mean=b,sd=st))
}
</code></pre>
</div></div>
<hr>
<p>
Функция \(apost(…;…;…)\), упоминавшаяся ранее, считается следующим образом:
\(apost\left( {{Y}_{p}};{{\vartheta }^{*}};{{\theta }^{*}} \right)=prior\left( {{\vartheta }^{*}};{{\theta }^{*}} \right)*Like\left( {{Y}_{p}} \right)\);
где \(prior\left( {{\vartheta }^{*}};{{\theta }^{*}} \right)={{P}_{g}}\left( \frac{1}{{{\vartheta }^{*}}};\alpha ;\frac{1}{\beta } \right)*\underset{i=0}{\overset{k}{\mathop \prod }}\,{{P}_{n}}\left( {{\theta }^{*}}_{i};{{\theta }_{i}};{{S}_{i}} \right)\)
– априорная вероятность;
\(Like\left( {{Y}_{p}} \right)=\underset{i=1}{\overset{n}{\mathop \prod }}\,{{P}_{n}}\left( {{Y}_{p}}_{i};{{Y}_{i}};\sqrt{var\left( Y \right)} \right)\)
– функция правдоподобия;
\({{P}_{g}}\left( \frac{1}{{{\vartheta }^{*}}};\alpha ;\frac{1}{\beta } \right)\)
– функция, возвращающая значения функции гамма-распределения с параметрами
\(\alpha\) и \(\frac{1}{\beta }\); \({{P}_{n}}\left( {{\theta }^{*}}_{i};{{\theta }_{i}};{{S}_{i}} \right)\)
– функция, возвращающая значения функции нормального распределения с средней
\({{\theta }_{i}}\) и стандартным отклонением
\({{S}_{i}}\).
При практических расчетах значения вероятностей заменялись значениями логарифмов вероятности,
так как в этом случае перемножение вероятностей заменяется суммированием логарифмов вероятностей
и расчеты происходят значительно быстрее.
</p>
<div class="code">
<div class="code_header">
  <a onclick="show_hide('code_11')" href="javascript:void(0);">Код в R (<em>показать</em>):</a>
</div>
<div id="code_11" class="code_lines_hide">
<pre><code  class="language-R line-numbers">#aprior likelyhood
prior &lt;- function(b, sig_sq, b_TH, alpha, beta, stdp)
{
  dn &lt;- dnorm(b, mean=b_TH, sd=stdp, log=T)
  dg &lt;- dgamma(1/sig_sq, shape=alpha, scale=1/beta, log=T)
  return(sum(dn)+dg)
}

#likelyhood function
likelyhood &lt;- function(b, Y, pY)
{
  st &lt;- sqrt(var(pY))
  dn &lt;- dnorm(Y, mean = pY, sd = st, log = T)
  return(sum(dn))
}

#aposterior likelyhood
aposterior &lt;- function(b, sig_sq, b_TH, alpha, beta, stdp, Y, pY)
{
  return(prior(b, sig_sq, b_TH, alpha, beta, stdp)+likelyhood(b, Y, pY))
}
</code></pre>
</div></div>
<hr>
<p><b><i>Код программы полностью (<a href="https://github.com/BigIskander/mcmc" target="_blank">скачать</a>).</i></b></p>
<div class="code">
<div class="code_header">
  <a onclick="show_hide('code_12')" href="javascript:void(0);">Код в R (<em>показать</em>):</a>
</div>
<div id="code_12" class="code_lines_hide">
<pre data-src="https://github.com/BigIskander/mcmc" data-download-link><code  class="language-R line-numbers">#Metropolis-Hastings MCMC algorithm implementation
#https://bigiskander.github.io/mcmc.html
#author: Sultanov Iskander
# &#66;&#105;&#103;&#73;&#115;&#107;&#97;&#110;&#100;&#101;&#114;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;

#aprior likelyhood
prior &lt;- function(b, sig_sq, b_TH, alpha, beta, stdp)
{
  dn &lt;- dnorm(b, mean=b_TH, sd=stdp, log=T)
  dg &lt;- dgamma(1/sig_sq, shape=alpha, scale=1/beta, log=T)
  return(sum(dn)+dg)
}

#likelyhood function
likelyhood &lt;- function(b, Y, pY)
{
  st &lt;- sqrt(var(pY))
  dn &lt;- dnorm(Y, mean = pY, sd = st, log = T)
  return(sum(dn))
}

#aposterior likelyhood
aposterior &lt;- function(b, sig_sq, b_TH, alpha, beta, stdp, Y, pY)
{
  return(prior(b, sig_sq, b_TH, alpha, beta, stdp)+likelyhood(b, Y, pY))
}

#generate new varibles
propose &lt;- function(b, st)
{
  return(rnorm(length(b),mean=b,sd=st))
}

#mcmc simulation
#iter - number of iterations
#X, Y - curent data
#b_TH - vector of coeffients from previous data estimation
#alpha, beta - gamma distribution parameters from previous data estimation
#h, L - accuracy variables from previous data estimation
mcmc &lt;- function(iter, X, Y, b_TH, alpha, beta, h, L)
{
  #preliminary estimation 1
  B &lt;- h*L
  C &lt;- matrix(0, length(b_TH), 1)
  for(i in 1:length(b_TH))
  {
    C[i] &lt;- B[i,i]-B[i,-i]%*%solve(B[-i,-i],B[-i,i])
  }
  stdp &lt;- 1/sqrt(C)

  #preliminary estimation 2
  iter &lt;- iter*1.1
  b &lt;- b_TH
  pY &lt;- X%*%b
  resid &lt;- Y-pY
  sig_sq &lt;- as.numeric(var(resid))
  output=matrix(0,ncol=ncol(X)+1,nrow=iter)
  output[1,]=c(sig_sq,b)

  prevp &lt;- aposterior(b, sig_sq, b_TH, alpha, beta, stdp, Y, pY)

  #mcmc algorithm main cycle
  i &lt;- 2
  while(i&lt;=iter)
  {
    bn &lt;- propose(b, stdp)
    pY &lt;- X%*%bn
    residn &lt;- Y-pY
    sig_sqn &lt;- as.numeric(var(residn))
    ace &lt;- aposterior(bn, sig_sqn, b_TH, alpha, beta, stdp, Y, pY)
    if(log(runif(1))&lt;(ace-prevp)) {
      b &lt;- bn
      sig_sq &lt;- sig_sqn
      prevp &lt;- ace
    }
    output[i,]=c(sig_sq,b)
    i &lt;- i+1
  }
  return(output[-c(1:(iter/11)),])
}

#dencity plot
dence &lt;- function(data)
{
  cc &lt;- ncol(data)
  if(cc&gt;3)
  {
    mm &lt;- round(cc/3,0)
    if(mm&lt;cc/3) mm &lt;- mm+1
    par(mfrow=c(mm,3))
  } else {
    par(mfrow=c(1,cc))
  }
  #dencity
  for(i in 2:cc)
  {
    hist(data[,i],breaks=150,main=paste0("th",(i-2)),freq=FALSE)
    lines(density(data[,i],bw="nrd",
                  kernel="gaussian"),col="red",lwd=2)
  }
  i &lt;- 1
  hist(data[,i],breaks=150,main="sig_sq",freq=FALSE)
  lines(density(data[,1],bw="nrd",kernel="gaussian"),col="red",lwd=2)
}

#example how you can calculate variables necessary for the algorithm
#and make calculations using this implementation of MCMC algorithm


#load the data
library(foreign)
#file with data saved in stata format (not provided)
mydata &lt;- read.dta("D:/Учеба/ВШЭ Аспирантура/Science/Calc in Stata/470.dta")
#econometric model for estimation (for example only)
f &lt;- "YS~Leverage+LN_Maturity+LN_Issue"

# 2014 excluded because of too smal number of observations
#estimate linear regressions
m1 &lt;- lm(f, mydata, year==2007)
m2 &lt;- lm(f, mydata, year==2008)
m3 &lt;- lm(f, mydata, year==2009)
m4 &lt;- lm(f, mydata, year==2010)
m5 &lt;- lm(f, mydata, year==2011)
m6 &lt;- lm(f, mydata, year==2012)
m7 &lt;- lm(f, mydata, year==2013)
#m8 &lt;- lm(f, mydata, year==2014)

#get coefficients (theta)
cf1 &lt;- coef(m1)
cf2 &lt;- coef(m2)
cf3 &lt;- coef(m3)
cf4 &lt;- coef(m4)
cf5 &lt;- coef(m5)
cf6 &lt;- coef(m6)
cf7 &lt;- coef(m7)
#cf8 &lt;- coef(m8)

#primary estimations
hh &lt;- 1/c(var(residuals(m1)),var(residuals(m2)),
          var(residuals(m3)),var(residuals(m4)),
          var(residuals(m5)),var(residuals(m6)),
          var(residuals(m7)))#,var(residuals(m8)))
h &lt;- mean(hh)
st_h &lt;- sqrt(var(hh))

#calc the distribution params
alpha &lt;- (h^2)/(st_h^2)
beta &lt;- h/(st_h^2)

ll &lt;- length(cf1)

cfl &lt;- matrix(0, ll, 7) #8
th &lt;- matrix(0, ll, 1)
st_th &lt;- matrix(0, ll, 1)
#L matrix calculation
L &lt;- matrix(0, ll, ll)
for(i in 1:ll)
{
  cfl[i,] &lt;- c(cf1[i],cf2[i],cf3[i],cf4[i],cf5[i],
               cf6[i],cf7[i])#,cf8[i])
  th[i] &lt;- mean(cfl[i,])
  st_th[i] &lt;- sqrt(var(cfl[i,]))
  L[i,i] &lt;- (1/(st_th[i]^2))*(beta/(alpha-1))
}

#get X and Y
ndata &lt;- subset(mydata, year==2015)
M &lt;- as.matrix(model.frame(formula=f, data=ndata))
Y &lt;- M[,1]
X &lt;- cbind(1,M[,-1])
n &lt;- length(Y)

#estimate using MCMC
iter &lt;- 1000000
data &lt;- mcmc(iter, X, Y, th, alpha, beta, h, L)

#get model parameters from MCMC estimation
th_sim &lt;- matrix(0,ncol(data)-1,1)
for(i in 2:ncol(data)) th_sim[i-1] &lt;- rbind(mean(data[,i]))
print(th_sim)

#plot dencity graphs
dence(data)
</code></pre>
</div></div>
<hr>
<p>Результат вычислений на моих данных приведенным выше кодом (только для примера):</p>
<p><img src="/assets/images/mcmc/values.PNG"></p>
<p><img src="/assets/images/mcmc/Rplot.png"></p>

	</div>
  <div class="to_top">
    <a href="JavaScript:scroll(0,0);" >
    <img src="/assets/images/top.png" width="50" alt="На верх!" />
    </a>
  </div>
  <div class="image_zoom_div">
    <img class="image_zoom" />
    <div class="zoom_me_out">Нажмите на изображение чтобы уменьшить.</div>
  </div>
  </body>
</html>
